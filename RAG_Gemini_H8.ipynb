{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adikahnf/learn-llm-based-tools/blob/main/RAG_Gemini_H8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Materi ini di buat oleh : [Sardi Irfansyah](https://www.linkedin.com/in/sirfansyah/)**"
      ],
      "metadata": {
        "id": "VmL_7tO-JdHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalasi Library"
      ],
      "metadata": {
        "id": "U2fk0vjajJRa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaBAFqqyoAGB"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai langchain langchain-google-genai langchain_community pypdf chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVWBkGqO0SeK",
        "outputId": "0bb9b8e7-2e3d-4c87-e74a-668868c4e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "0GwLF-rp0k_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "G5w_JgRBCeUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# masukan API key kalian\n",
        "api_key= userdata.get('API_KEY')\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "7CiFYWa0zoNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatGoogleGenerativeAI(google_api_key=api_key,\n",
        "                                   model=\"gemini-1.5-pro-latest\")"
      ],
      "metadata": {
        "id": "A_inEdIozpdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download pdf dengan curl\n",
        "!curl -o  ai_pv.pdf https://www.pearsonvue.com/content/dam/VUE/vue/en/documents/clients/it-specialist/its-od-307-artificial-intel-pearson.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6QOb3Tn1byn",
        "outputId": "cbd8f0bb-463d-4511-f96e-41a7e9d00009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  250k  100  250k    0     0   269k      0 --:--:-- --:--:-- --:--:--  268k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"ai_pv.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "gYFSOtpg1WvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "n2O2AzXb25d7",
        "outputId": "bf5c1e58-2832-4f89-ec32-b975d5bc7ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Copyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. \\n1. AI Problem Definition\\n1.1 Identify the problem you are trying to solve using AI (e.g., user \\nsegmentation, improving customer service)\\n• Identify the need that will be addressed\\n• Find out what information comes in and what output is expected\\n• Determine whether AI is called for\\n• Consider upsides and downsides of AI in the situation\\n• Define measurable success\\n• Benchmark against domain or organization-specific risks to which the \\nproject may be susceptible\\n1.2 Classify the problem (e.g., regression, unsupervised learning) \\n• Examine available data (labeled or unlabeled?) and the problem\\n• Determine problem type (e.g., classification, regression, unsupervised, \\nreinforcement)\\n1.3 Identify the areas of expertise needed to solve the problem\\n• Identify business expertise required\\n• Identify the need for domain (subject-matter) expertise on the problem\\n• Identify AI expertise needed\\n• Identify implementation expertise needed\\nIT SPECIALIST EXAM OBJECTIVES\\nArtificial Intelligence\\nCandidates for this certification have a foundational knowledge the procedures used to develop an artificial \\nintelligence (AI) solution, as well as an understanding of the issues surrounding the governance, transparency, \\nsecurity, and ethics of AI.  Successful candidates will be able to analyze and classify a problem. They should \\nbe able to demonstrate knowledge of data collection, data processing, and feature engineering strategies. \\nCandidates should be able to choose an appropriate algorithm for training a model, and understand the \\nmetrics used to evaluate model performance. They should understand the AI development lifecycle and \\nhow a production pipeline is used to allow for continuous improvement.  Candidates at least 150 hours of \\ninstruction and/or exploration of artificial intelligence methodology and solutions.\\nTo be successful on the test, the candidate is also expected to have the following prerequisite knowledge \\nand skills:\\n• 8th grade reading skills\\n• Algebra I\\n• An understanding of how communication occurs on a network\\n• Digital literacy skills, including the ability to research, create content, and solve problems using \\ntechnology\\n• Computational thinking skills, including the ability to decompose a problem into smaller parts and \\nsolve problems through automation\\nAlthough not required, the following skills will help a candidate learn about artificial intelligence more \\neasily:\\n• Familiarity with at least one programming or scripting language\\n• Familiarity with data storage technologies, including relational databases\\n• Familiarity with data analytics methods, including statistics \\n• Familiarity with security principles, including CIA (confidentiality, identity, and availability) and AAA \\n(Authentication, Authorization, and Accounting), and risk and vulnerability assessment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iij5ZCd43aJ2",
        "outputId": "9cb2e377-28ca-4b9e-f7b4-15c0558de4b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunk"
      ],
      "metadata": {
        "id": "WkGKW3ky3eGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvjHxw-Y3sex",
        "outputId": "4216a4f5-5a03-4286-e550-a00bc5592bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agar lebih terbanyang tentang penerapan chunk, kita akan uji coba terlebih dahulu dengan text sederhana."
      ],
      "metadata": {
        "id": "SDj5KMeAkCRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import NLTKTextSplitter\n",
        "\n",
        "# Misalkan kamu memiliki dokumen seperti berikut\n",
        "simple_doc = \"\"\"halo nama saya sardi irfansyah, saya lahir di jakarta. Saya irfan. tinggal di Jakarta.\"\"\"\n",
        "print('panjang total karakter:',len(simple_doc),'\\n')\n",
        "# Membuat objek NLTKTextSplitter dengan ukuran chunk dan overlap\n",
        "text_splitter = NLTKTextSplitter(separator='\\n\\n',chunk_size=67, chunk_overlap=10) #default separator='\\n\\n'\n",
        "\n",
        "# Memecah dokumen menjadi beberapa chunk\n",
        "chunks = text_splitter.split_text(simple_doc)\n",
        "print(chunks,'\\n')\n",
        "\n",
        "# Menampilkan hasil chunk\n",
        "for i, chunk in enumerate(chunks):\n",
        "    #panjang karakter\n",
        "    print(f\"Panjang chunk {i+1}: {len(chunk)} karakter\")\n",
        "    print(f\"Chunk {i+1}:\")\n",
        "    print(chunk)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG_Y9bBCisg_",
        "outputId": "537fc64c-9fb1-433f-cbe1-9c4cff941a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "panjang total karakter: 86 \n",
            "\n",
            "['halo nama saya sardi irfansyah, saya lahir di jakarta.\\n\\nSaya irfan.', 'tinggal di Jakarta.'] \n",
            "\n",
            "Panjang chunk 1: 67 karakter\n",
            "Chunk 1:\n",
            "halo nama saya sardi irfansyah, saya lahir di jakarta.\n",
            "\n",
            "Saya irfan.\n",
            "--------------------------------------------------\n",
            "Panjang chunk 2: 19 karakter\n",
            "Chunk 2:\n",
            "tinggal di Jakarta.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan:\n",
        "- Dapat kita lihat bahwa `NLTKTextSplitter` akan mencoba membuat text tersebut dipisahkan berdasarkan kalimat atau tanda `titik`. Jadi setiap ada titik maka akan dibuat chunk.\n",
        "- Ketika panjang karakter lebih dari `chunk_size`, ini akan mengakibatkan peringatan warning.\n",
        "- `chunk_overlap` digunakan untuk menentukan jumlah karakter yang harus tumpang tindih antara chunk yang berdekatan.\n",
        "\n",
        "Jika anda ingin melihat ilustrasi tentang konfigurasi chunk, anda dapat melihatnya [di sini](https://dev.to/peterabel/what-chunk-size-and-chunk-overlap-should-you-use-4338)."
      ],
      "metadata": {
        "id": "JmP5jX-ukUKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita akan coba terapkan proses pemisahan kalimat ke dokumen yang kita gunakan."
      ],
      "metadata": {
        "id": "7VczgW8lsyDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import NLTKTextSplitter\n",
        "\n",
        "text_splitter = NLTKTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "print(len(chunks))\n",
        "\n",
        "print(type(chunks[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "213C34UZ3dA3",
        "outputId": "74f41092-a3de-498a-9873-4c3d1f73e986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 579, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 660, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 801, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 522, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1277, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 797, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "<class 'langchain_core.documents.base.Document'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek hasil pemecahan menjadi chunk\n",
        "print(f\"Jumlah chunks yang dihasilkan: {len(chunks)}\")\n",
        "print(f\"Tipe data chunk pertama: {type(chunks[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbVa5yqgdHA",
        "outputId": "9c8487a0-e538-4d45-e208-55323d3aba6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah chunks yang dihasilkan: 19\n",
            "Tipe data chunk pertama: <class 'langchain_core.documents.base.Document'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len('and the problem'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2_k0m9t4_K",
        "outputId": "e94544c7-3a3a-4893-eaa3-4566ae40579f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan chunk pertama\n",
        "# panjang chunk\n",
        "print(f\"Panjang chunk pertama: {len(chunks[0].page_content)} karakter\")\n",
        "print(\"\\nContoh chunk pertama:\")\n",
        "print(chunks[0].page_content)  # Memastikan bahwa setiap chunk memiliki konten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uNGIF0ziJaX",
        "outputId": "464b47fb-9731-4913-a8da-ac4f46491f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panjang chunk pertama: 87 karakter\n",
            "\n",
            "Contoh chunk pertama:\n",
            "Copyright © 2023 Pearson Education, Inc. or its affiliate(s).\n",
            "\n",
            "All rights reserved.\n",
            "\n",
            "1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "3cCRgGgexjnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Embedding setelah melakukan Chunking."
      ],
      "metadata": {
        "id": "Sf2antgQ489n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=api_key, model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "2XINgy-y3tnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Databases"
      ],
      "metadata": {
        "id": "0UMmS8_Rxocg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cek dokumentasi [vector store](https://python.langchain.com/docs/how_to/vectorstore_retriever/)."
      ],
      "metadata": {
        "id": "BcSUClmC5HMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Sematkan setiap chunk dan muat ke dalam chromadb\n",
        "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
        "\n",
        "# Menyimpan perubahan ke disk\n",
        "db.persist()"
      ],
      "metadata": {
        "id": "uQXMJt3V5Hn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb34e6f-1a56-4283-f85c-0ba8949dd8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-489a92d48a2b>:7: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  db.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mengatur koneksi untuk menghubungkan ke ChromaDB\n",
        "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
      ],
      "metadata": {
        "id": "8jX0NFtX5ezK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd9be26-bcfb-416a-c4fe-bcff2b7f6f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-a3634a9c7fb4>:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengonversi koneksi Chroma menjadi objek retriever untuk pencarian dokumen berbasis vektor\n",
        "retriever = db_connection.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "print(type(retriever))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjLBoS_0DWnj",
        "outputId": "845dfc4e-d302-4d33-cc8a-c37f363d8cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`k` adalah parameter yang digunakan dalam fungsi as_retriever() untuk menentukan jumlah hasil pencarian teratas (top-k) yang akan diambil dari basis data vektor (Chroma database).\n",
        "\n",
        "Parameter ini digunakan dalam proses pencarian dokumen relevan yang mengacu pada jumlah dokumen atau chunk yang akan diambil dari kumpulan dokumen yang lebih besar (misalnya, dari Chroma vector store) berdasarkan kesamaan atau kedekatannya dengan pertanyaan yang diajukan.\n",
        "\n",
        "> Nilai k umumnya lebih kecil dari total chunk.\n",
        "\n"
      ],
      "metadata": {
        "id": "8JeHWwPTydZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_response = retriever.invoke(\"jelaskan skill yang dibutuhkan untuk sertifikasi pearson vue dalam bidang AI?\")\n",
        "len(check_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xgjpoCEyTbh",
        "outputId": "666a3c49-0c13-4573-d208-3aafa5164046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "md(check_response[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "vN-KIM46zhLA",
        "outputId": "1f9a192d-14b8-4db1-ec09-5d6b7186b7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "and the problem\n• Determine problem type (e.g., classification, regression, unsupervised, \nreinforcement)\n1.3 Identify the areas of expertise needed to solve the problem\n• Identify business expertise required\n• Identify the need for domain (subject-matter) expertise on the problem\n• Identify AI expertise needed\n• Identify implementation expertise needed\nIT SPECIALIST EXAM OBJECTIVES\nArtificial Intelligence\nCandidates for this certification have a foundational knowledge the procedures used to develop an artificial \nintelligence (AI) solution, as well as an understanding of the issues surrounding the governance, transparency, \nsecurity, and ethics of AI."
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt"
      ],
      "metadata": {
        "id": "ssrSfilNzV90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dokumnetasi [Prompt templates](https://python.langchain.com/docs/concepts/prompt_templates/)."
      ],
      "metadata": {
        "id": "yEXuR_L61Zgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
      ],
      "metadata": {
        "id": "0mXQhAqDDYqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat template pesan untuk sistem dan pesan pengguna\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    # System Message Prompt Template\n",
        "    SystemMessage(content=\"\"\"Anda adalah AI yang dapat menjawab pertanyaan berdasarkan konteks dan pertanyaan dari user.\n",
        "                 Anda harus menjawab pertanyaan user, berdasarkan konteks\"\"\"),\n",
        "\n",
        "    # Human Message Prompt Template\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"Jawab pertanyaan berikut berdasarkan konteks.\n",
        "    konteks: {context}\n",
        "    pertanyaan: {question}\n",
        "    jawaban: \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "kcT1coZUDmsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "nZVzOLvYDo1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "hHQpNgNt2cXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setelah dokumen diambil oleh retriever dan di-format\n",
        "formatted_docs = format_docs(chunks)  # Format dokumen yang dihasilkan dari text chunks\n",
        "\n",
        "# Cetak hasil format\n",
        "print(\"Hasil Format Docs:\")\n",
        "print(formatted_docs)  # Menampilkan hasil setelah dokumen diformat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9F_kjGxhoB0",
        "outputId": "ff19a00c-f546-4b78-feff-64162bdf365b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Format Docs:\n",
            "Copyright © 2023 Pearson Education, Inc. or its affiliate(s).\n",
            "\n",
            "All rights reserved.\n",
            "\n",
            "1.\n",
            "\n",
            "AI Problem Definition\n",
            "1.1 Identify the problem you are trying to solve using AI (e.g., user \n",
            "segmentation, improving customer service)\n",
            "• Identify the need that will be addressed\n",
            "• Find out what information comes in and what output is expected\n",
            "• Determine whether AI is called for\n",
            "• Consider upsides and downsides of AI in the situation\n",
            "• Define measurable success\n",
            "• Benchmark against domain or organization-specific risks to which the \n",
            "project may be susceptible\n",
            "1.2 Classify the problem (e.g., regression, unsupervised learning) \n",
            "• Examine available data (labeled or unlabeled?)\n",
            "\n",
            "and the problem\n",
            "• Determine problem type (e.g., classification, regression, unsupervised, \n",
            "reinforcement)\n",
            "1.3 Identify the areas of expertise needed to solve the problem\n",
            "• Identify business expertise required\n",
            "• Identify the need for domain (subject-matter) expertise on the problem\n",
            "• Identify AI expertise needed\n",
            "• Identify implementation expertise needed\n",
            "IT SPECIALIST EXAM OBJECTIVES\n",
            "Artificial Intelligence\n",
            "Candidates for this certification have a foundational knowledge the procedures used to develop an artificial \n",
            "intelligence (AI) solution, as well as an understanding of the issues surrounding the governance, transparency, \n",
            "security, and ethics of AI.\n",
            "\n",
            "Successful candidates will be able to analyze and classify a problem.\n",
            "\n",
            "They should \n",
            "be able to demonstrate knowledge of data collection, data processing, and feature engineering strategies.\n",
            "\n",
            "Candidates should be able to choose an appropriate algorithm for training a model, and understand the \n",
            "metrics used to evaluate model performance.\n",
            "\n",
            "They should understand the AI development lifecycle and \n",
            "how a production pipeline is used to allow for continuous improvement.\n",
            "\n",
            "Candidates at least 150 hours of \n",
            "instruction and/or exploration of artificial intelligence methodology and solutions.\n",
            "\n",
            "To be successful on the test, the candidate is also expected to have the following prerequisite knowledge \n",
            "and skills:\n",
            "• 8th grade reading skills\n",
            "• Algebra I\n",
            "• An understanding of how communication occurs on a network\n",
            "• Digital literacy skills, including the ability to research, create content, and solve problems using \n",
            "technology\n",
            "• Computational thinking skills, including the ability to decompose a problem into smaller parts and \n",
            "solve problems through automation\n",
            "Although not required, the following skills will help a candidate learn about artificial intelligence more \n",
            "easily:\n",
            "• Familiarity with at least one programming or scripting language\n",
            "• Familiarity with data storage technologies, including relational databases\n",
            "• Familiarity with data analytics methods, including statistics \n",
            "• Familiarity with security principles, including CIA (confidentiality, identity, and availability) and AAA \n",
            "(Authentication, Authorization, and Accounting), and risk and vulnerability assessment\n",
            "\n",
            "Copyright © 2023 Pearson Education, Inc. or its affiliate(s).\n",
            "\n",
            "All rights reserved.\n",
            "\n",
            "1.4 Build a security plan\n",
            "• Consider internal access levels or permissions\n",
            "• Consider infrastructure security\n",
            "• Assess the risk of using a certain model or potential attack surfaces (e.g., \n",
            "adversarial attacks on real-time learning model)\n",
            "1.5 Ensure that AI is used appropriately\n",
            "• Identify potential ways that the AI can mispredict or harm specific user \n",
            "groups\n",
            "• Set guidelines for data gathering and use\n",
            "• Set guidelines for algorithm selection from user perspective\n",
            "• Consider how the subject of the data can interpret the results\n",
            "• Consider out-of-context use of AI results\n",
            "1.6 Choose transparency and validation activities\n",
            "• Communicate intended purpose of data collection\n",
            "• Decide who should see the results\n",
            "• Review legal requirements specific to the industry with the problem being \n",
            "solved\n",
            "2.\n",
            "\n",
            "Data Collection, Processing, and Engineering \n",
            "2.1 Choose the way to collect data\n",
            "• Determine type/characteristics of data needed\n",
            "• Decide if there is an existing dataset or if you need to generate your own\n",
            "• When generating your own dataset, decide whether collection can be \n",
            "automated or requires user input\n",
            "2.2 Assess data quality     \n",
            "• Determine whether the dataset meets needs of task\n",
            "• Look for missing or corrupt data elements\n",
            "2.3 Ensure that data are representative  \n",
            "• Examine collection techniques for potential sources of bias\n",
            "• Make sure the amount of data is enough to build an unbiased model\n",
            "2.4 Identify resource requirements (e.g., computing, time complexity)\n",
            "• Assess whether the problem is solvable with available computing resources\n",
            "• Consider the budget of the project and the resources that are available\n",
            "2.5 Convert data into suitable formats (e.g., numerical, image, time \n",
            "series)\n",
            "• Convert data to binary (e.g., images become pixels)\n",
            "• Convert computer data into features suitable for AI (e.g., sentences \n",
            "become tokens)\n",
            "2.6 Select features for the AI model \n",
            "• Determine which data features to include \n",
            "• Build initial feature vectors for test/train dataset\n",
            "• Consult with subject-matter experts to confirm feature selection\n",
            "IT SPECIALIST EXAM OBJECTIVES\n",
            "\n",
            "Copyright © 2023 Pearson Education, Inc. or its affiliate(s).\n",
            "\n",
            "All rights reserved.\n",
            "\n",
            "IT SPECIALIST EXAM OBJECTIVES\n",
            "2.7 Engage in feature engineering\n",
            "• Review features and determine what standard transformations are needed\n",
            "• Create processed datasets\n",
            "2.8 Identify training and test datasets \n",
            "• Separate available data into training and test datasets\n",
            "• Ensure test dataset is represented \n",
            "2.9 Document data decisions   \n",
            "• List assumptions, predicates, and constraints upon which design choices \n",
            "have been reasoned\n",
            "• Make this information available to regulators and end users who demand \n",
            "deep transparency \n",
            "3.\n",
            "\n",
            "AI Algorithms and Models  \n",
            "3.1 Consider applicability of specific algorithms \n",
            "• Evaluate AI algorithm families\n",
            "• Decide which algorithms  are suitable, e.g., neural network, classification \n",
            "(like decision tree, k means)\n",
            "3.2 Train a model using the selected algorithm \n",
            "• Train model for an algorithm with best-guess starting parameters.\n",
            "\n",
            "• Tune the model by changing parameters\n",
            "• Gather performance metrics for the model\n",
            "• Iterate as needed\n",
            "3.3 Select specific model after experimentation, avoiding \n",
            "overengineering\n",
            "• Consider cost, speed, and other factors in evaluating models\n",
            "• Determine whether selected model meets explainability requirements\n",
            "3.4 Tell data stories \n",
            "• Where feasible, create visualizations of the results\n",
            "• Look for trends\n",
            "• Verify that the visualization is useful for making a decision\n",
            "3.5 Evaluate model performance (e.g., accuracy, precision)\n",
            "• Check for overfitting, underfitting\n",
            "• Generate metrics or KPIs\n",
            "• Introduce new test data to cross-validate robustness, testing how model \n",
            "handles unforeseen data\n",
            "3.6 Look for potential sources of bias in the algorithm\n",
            "• Verify that inputs resemble training data\n",
            "• Confirm that training data do not contain irrelevant correlations we do not \n",
            "want classifier to rely on\n",
            "• Check for imbalances in data\n",
            "• Guard against creating self-fulfilling prophecies based upon historical \n",
            "biases\n",
            "• Check the explainability of the algorithm (e.g., feature importance in \n",
            "decision trees)\n",
            "\n",
            "Copyright © 2023 Pearson Education, Inc. or its affiliate(s).\n",
            "\n",
            "All rights reserved.\n",
            "\n",
            "IT SPECIALIST EXAM OBJECTIVES\n",
            "3.7 Evaluate model sensitivity \n",
            "• Test for sensitivity of model\n",
            "• Test for specificity of model\n",
            "3.8 Confirm adherence to regulatory requirements, if any \n",
            "• Evaluate outputs according to thresholds defined in requirements\n",
            "• Document results\n",
            "3.9 Obtain stakeholder approval\n",
            "• Collect results and benchmark risks\n",
            "• Hold sessions to evaluate solution\n",
            "4.\n",
            "\n",
            "Application Integration and Deployment\n",
            "4.1 Train customers on how to use product and what to expect from it\n",
            "• Inform users of model limitations\n",
            "• Inform users of intended model usage\n",
            "• Share documentation\n",
            "• Manage customer expectations\n",
            "4.2 Plan to address potential challenges of models in production\n",
            "• Understand the types of challenges you are likely to encounter\n",
            "• Understand the indicators of challenges\n",
            "• Understand how each type of challenge could be mitigated\n",
            "4.3 Design a production pipeline, including application integration\n",
            "• Create a pipeline (training, prediction) that can meet the product needs \n",
            "(may be different from the experiment)\n",
            "• Find the solution that works with the existing data stores and connects to \n",
            "the application\n",
            "• Build the connection between the AI and the application\n",
            "• Build mechanism to gather user feedback\n",
            "• Test accuracy of AI through application\n",
            "• Test robustness of AI\n",
            "• Test speed of AI\n",
            "• Test application to fit size of use case (e.g., in AI for mobile applications)\n",
            "4.4 Support the AI solution\n",
            "• Document the functions within the AI solution to allow for maintenance \n",
            "(updates, fixing bugs, handling edge cases)\n",
            "• Train a support team\n",
            "• Implement a feedback mechanism\n",
            "• Implement drift detector\n",
            "• Implement ways to gather new data\n",
            "5.\n",
            "\n",
            "Maintaining and Monitoring AI in Production \n",
            "5.1 Engage in oversight\n",
            "• Log application and model performance to facilitate security, debug, \n",
            "accountability, and audit\n",
            "• Use robust monitoring systems\n",
            "\n",
            "Copyright © 2023 Pearson Education, Inc. or its affiliate(s).\n",
            "\n",
            "All rights reserved.\n",
            "\n",
            "IT SPECIALIST EXAM OBJECTIVES\n",
            "• Act upon alerts\n",
            "• Observe the system over time in a variety of contexts to check for drift or \n",
            "degraded modes of operation\n",
            "• Detect any way system fails to support new information\n",
            "5.2 Assess business impact (key performance indicators)\n",
            "• Track impact metrics to determine whether solution has solved the \n",
            "problem\n",
            "• Compare previous metrics with new metrics when changes are made\n",
            "• Act on unexpected metrics by finding problem and fixing it\n",
            "5.3 Measure impacts on individuals and communities\n",
            "• Analyze impact on specific subgroups\n",
            "• Identify and mitigate issues\n",
            "• Identify opportunities for optimization\n",
            "5.4 Handle feedback from users\n",
            "• Measure user satisfaction\n",
            "• Assess whether users are confused (e.g., do they understand what the AI is \n",
            "supposed to do for them?)\n",
            "\n",
            "• Incorporate feedback into future versions\n",
            "5.5 Consider improvement or decommission on a regular basis\n",
            "• Combine impact observations (e.g., business, community, technology \n",
            "trends) to assess AI value\n",
            "• Decide whether to retrain AI, continue to use AI as is, or to decommission \n",
            "AI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | chat_template\n",
        "    | chat_model\n",
        "    | output_parser\n",
        ")\n"
      ],
      "metadata": {
        "id": "-vrZd5wuDqlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"\"\"beritahu saya pemahaman apa yang dibutuhkan untuk sertifikasi IT spesialis: AI dari pearson vue\"\"\")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "JdJOGcTODs0U",
        "outputId": "c8bbca31-86b6-4e95-ea82-0961ce426fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Untuk mendapatkan sertifikasi IT Specialist: AI dari Pearson VUE, kandidat harus memiliki pemahaman dasar tentang prosedur yang digunakan untuk mengembangkan solusi kecerdasan buatan (AI), serta pemahaman tentang isu-isu seputar tata kelola, transparansi, keamanan, dan etika AI.  \\n\\nLebih spesifik, kandidat perlu memahami:\\n\\n* **Analisis dan Klasifikasi Masalah:**  Mampu menganalisis dan mengklasifikasikan jenis masalah (klasifikasi, regresi, unsupervised, reinforcement learning).\\n* **Pengumpulan, Pemrosesan, dan Rekayasa Data:** Memahami strategi pengumpulan data, pemrosesan data, dan *feature engineering*.  Ini termasuk memilih metode pengumpulan data, menilai kualitas data, memastikan representasi data, mengidentifikasi kebutuhan sumber daya, mengkonversi data ke format yang sesuai, memilih dan merekayasa fitur, serta mendokumentasikan keputusan terkait data.\\n* **Algoritma dan Model AI:** Mengetahui berbagai algoritma AI dan memilih algoritma yang tepat untuk melatih model.  Kandidat juga harus memahami metrik yang digunakan untuk mengevaluasi kinerja model.  Ini termasuk melatih model, menguji dan men-debug, mengevaluasi sensitivitas model, dan memastikan kepatuhan terhadap persyaratan peraturan.\\n* **Siklus Hidup Pengembangan AI dan *Production Pipeline*:** Memahami siklus hidup pengembangan AI dan bagaimana *production pipeline* digunakan untuk memungkinkan peningkatan berkelanjutan. Ini termasuk menyebarkan dan mengintegrasikan model, memantau kinerja, menilai dampak bisnis dan sosial, menangani umpan balik pengguna, dan mempertimbangkan peningkatan atau penghentian sistem AI.\\n\\nSelain itu, kandidat diharapkan memiliki pengetahuan dan keterampilan prasyarat berikut:\\n\\n* Kemampuan membaca setara kelas 8\\n* Aljabar I\\n* Pemahaman tentang bagaimana komunikasi terjadi di jaringan\\n* Keterampilan literasi digital\\n* Keterampilan berpikir komputasional\\n\\nMeskipun tidak diwajibkan, beberapa keterampilan berikut akan membantu kandidat mempelajari tentang kecerdasan buatan dengan lebih mudah:\\n\\n* Keakraban dengan setidaknya satu bahasa pemrograman atau *scripting*\\n* Keakraban dengan teknologi penyimpanan data, termasuk basis data relasional\\n* Keakraban dengan metode analisis data, termasuk statistik\\n* Keakraban dengan prinsip-prinsip keamanan\\n\\nKandidat juga diharuskan memiliki setidaknya 150 jam instruksi dan/atau eksplorasi metodologi dan solusi kecerdasan buatan.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "md(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "8Fxlr1hlD9Ij",
        "outputId": "925cc14d-7a09-4934-cbe9-677537782b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Untuk mendapatkan sertifikasi IT Specialist: AI dari Pearson VUE, kandidat harus memiliki pemahaman dasar tentang prosedur yang digunakan untuk mengembangkan solusi kecerdasan buatan (AI), serta pemahaman tentang isu-isu seputar tata kelola, transparansi, keamanan, dan etika AI.  \n\nLebih spesifik, kandidat perlu memahami:\n\n* **Analisis dan Klasifikasi Masalah:**  Mampu menganalisis dan mengklasifikasikan jenis masalah (klasifikasi, regresi, unsupervised, reinforcement learning).\n* **Pengumpulan, Pemrosesan, dan Rekayasa Data:** Memahami strategi pengumpulan data, pemrosesan data, dan *feature engineering*.  Ini termasuk memilih metode pengumpulan data, menilai kualitas data, memastikan representasi data, mengidentifikasi kebutuhan sumber daya, mengkonversi data ke format yang sesuai, memilih dan merekayasa fitur, serta mendokumentasikan keputusan terkait data.\n* **Algoritma dan Model AI:** Mengetahui berbagai algoritma AI dan memilih algoritma yang tepat untuk melatih model.  Kandidat juga harus memahami metrik yang digunakan untuk mengevaluasi kinerja model.  Ini termasuk melatih model, menguji dan men-debug, mengevaluasi sensitivitas model, dan memastikan kepatuhan terhadap persyaratan peraturan.\n* **Siklus Hidup Pengembangan AI dan *Production Pipeline*:** Memahami siklus hidup pengembangan AI dan bagaimana *production pipeline* digunakan untuk memungkinkan peningkatan berkelanjutan. Ini termasuk menyebarkan dan mengintegrasikan model, memantau kinerja, menilai dampak bisnis dan sosial, menangani umpan balik pengguna, dan mempertimbangkan peningkatan atau penghentian sistem AI.\n\nSelain itu, kandidat diharapkan memiliki pengetahuan dan keterampilan prasyarat berikut:\n\n* Kemampuan membaca setara kelas 8\n* Aljabar I\n* Pemahaman tentang bagaimana komunikasi terjadi di jaringan\n* Keterampilan literasi digital\n* Keterampilan berpikir komputasional\n\nMeskipun tidak diwajibkan, beberapa keterampilan berikut akan membantu kandidat mempelajari tentang kecerdasan buatan dengan lebih mudah:\n\n* Keakraban dengan setidaknya satu bahasa pemrograman atau *scripting*\n* Keakraban dengan teknologi penyimpanan data, termasuk basis data relasional\n* Keakraban dengan metode analisis data, termasuk statistik\n* Keakraban dengan prinsip-prinsip keamanan\n\nKandidat juga diharuskan memiliki setidaknya 150 jam instruksi dan/atau eksplorasi metodologi dan solusi kecerdasan buatan."
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contoh lain"
      ],
      "metadata": {
        "id": "eq5k0hFWAiT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "misalkan pada contoh ini kita akan mencoba menerapkan RAG\n",
        "dengan `RecursiveCharacterTextSplitter` dan `PromptTemplate`."
      ],
      "metadata": {
        "id": "D3kQ307BTu0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalasi dependensi yang dibutuhkan\n",
        "!pip install -q langchain PyPDF2 #python-dotenv"
      ],
      "metadata": {
        "id": "LcDeiZVWD5jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7ddf52-fdd6-4358-91f9-d4d9f60d0166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import PyPDF2\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "# from dotenv import load_dotenv\n",
        "from google.colab import files\n",
        "from IPython.display import Markdown as md"
      ],
      "metadata": {
        "id": "vhPusQHlG4bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuka dan membaca file PDF\n",
        "with open('/content/ai_pv.pdf', \"rb\") as file:\n",
        "    pdf_reader = PyPDF2.PdfReader(file)\n",
        "    pdf_pages = pdf_reader.pages\n",
        "\n",
        "    # Mengekstrak teks dari semua halaman\n",
        "    context = \"\\n\\n\".join(page.extract_text() for page in pdf_pages)"
      ],
      "metadata": {
        "id": "isqpnm6MFhxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "id": "XBwH3dVlFwm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "b1e74f7e-7774-4022-c1c2-ac6f51e42af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Copyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. \\n1. AI Problem Definition\\n1.1 Identify the problem you are trying to solve using AI (e.g., user \\nsegmentation, improving customer service)\\n• Identify the need that will be addressed\\n• Find out what information comes in and what output is expected\\n• Determine whether AI is called for\\n• Consider upsides and downsides of AI in the situation\\n• Define measurable success\\n• Benchmark against domain or organization-specific risks to which the \\nproject may be susceptible\\n1.2 Classify the problem (e.g., regression, unsupervised learning) \\n• Examine available data (labeled or unlabeled?) and the problem\\n• Determine problem type (e.g., classification, regression, unsupervised, \\nreinforcement)\\n1.3 Identify the areas of expertise needed to solve the problem\\n• Identify business expertise required\\n• Identify the need for domain (subject-matter) expertise on the problem\\n• Identify AI expertise needed\\n• Identify implementation expertise neededIT SPECIALIST EXAM OBJECTIVES\\nArtificial Intelligence\\nCandidates for this certification have a foundational knowledge the procedures used to develop an artificial \\nintelligence (AI) solution, as well as an understanding of the issues surrounding the governance, transparency, \\nsecurity, and ethics of AI.  Successful candidates will be able to analyze and classify a problem. They should \\nbe able to demonstrate knowledge of data collection, data processing, and feature engineering strategies. \\nCandidates should be able to choose an appropriate algorithm for training a model, and understand the \\nmetrics used to evaluate model performance. They should understand the AI development lifecycle and \\nhow a production pipeline is used to allow for continuous improvement.  Candidates at least 150 hours of \\ninstruction and/or exploration of artificial intelligence methodology and solutions.\\nTo be successful on the test, the candidate is also expected to have the following prerequisite knowledge \\nand skills:\\n• 8th grade reading skills\\n• Algebra I\\n• An understanding of how communication occurs on a network\\n• Digital literacy skills, including the ability to research, create content, and solve problems using \\ntechnology\\n• Computational thinking skills, including the ability to decompose a problem into smaller parts and \\nsolve problems through automation\\nAlthough not required, the following skills will help a candidate learn about artificial intelligence more \\neasily:\\n• Familiarity with at least one programming or scripting language\\n• Familiarity with data storage technologies, including relational databases\\n• Familiarity with data analytics methods, including statistics \\n• Familiarity with security principles, including CIA (confidentiality, identity, and availability) and AAA \\n(Authentication, Authorization, and Accounting), and risk and vulnerability assessment\\n\\nCopyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. 1.4 Build a security plan\\n• Consider internal access levels or permissions\\n• Consider infrastructure security\\n• Assess the risk of using a certain model or potential attack surfaces (e.g., \\nadversarial attacks on real-time learning model)\\n1.5 Ensure that AI is used appropriately\\n• Identify potential ways that the AI can mispredict or harm specific user \\ngroups\\n• Set guidelines for data gathering and use\\n• Set guidelines for algorithm selection from user perspective\\n• Consider how the subject of the data can interpret the results\\n• Consider out-of-context use of AI results\\n1.6 Choose transparency and validation activities\\n• Communicate intended purpose of data collection\\n• Decide who should see the results\\n• Review legal requirements specific to the industry with the problem being \\nsolved\\n2. Data Collection, Processing, and Engineering \\n2.1 Choose the way to collect data\\n• Determine type/characteristics of data needed\\n• Decide if there is an existing dataset or if you need to generate your own\\n• When generating your own dataset, decide whether collection can be \\nautomated or requires user input\\n2.2 Assess data quality     \\n• Determine whether the dataset meets needs of task\\n• Look for missing or corrupt data elements\\n2.3 Ensure that data are representative  \\n• Examine collection techniques for potential sources of bias\\n• Make sure the amount of data is enough to build an unbiased model\\n2.4 Identify resource requirements (e.g., computing, time complexity)\\n• Assess whether the problem is solvable with available computing resources\\n• Consider the budget of the project and the resources that are available\\n2.5 Convert data into suitable formats (e.g., numerical, image, time \\nseries)\\n• Convert data to binary (e.g., images become pixels)\\n• Convert computer data into features suitable for AI (e.g., sentences \\nbecome tokens)\\n2.6 Select features for the AI model \\n• Determine which data features to include \\n• Build initial feature vectors for test/train dataset\\n• Consult with subject-matter experts to confirm feature selectionIT SPECIALIST EXAM OBJECTIVES\\n\\nCopyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. IT SPECIALIST EXAM OBJECTIVES\\n2.7 Engage in feature engineering\\n• Review features and determine what standard transformations are needed\\n• Create processed datasets\\n2.8 Identify training and test datasets \\n• Separate available data into training and test datasets\\n• Ensure test dataset is represented \\n2.9 Document data decisions   \\n• List assumptions, predicates, and constraints upon which design choices \\nhave been reasoned\\n• Make this information available to regulators and end users who demand \\ndeep transparency\\u2003\\n3. AI Algorithms and Models  \\n3.1 Consider applicability of specific algorithms \\n• Evaluate AI algorithm families\\n• Decide which algorithms  are suitable, e.g., neural network, classification \\n(like decision tree, k means)\\n3.2 Train a model using the selected algorithm \\n• Train model for an algorithm with best-guess starting parameters.\\n• Tune the model by changing parameters\\n• Gather performance metrics for the model\\n• Iterate as needed\\n3.3 Select specific model after experimentation, avoiding \\noverengineering\\n• Consider cost, speed, and other factors in evaluating models\\n• Determine whether selected model meets explainability requirements\\n3.4 Tell data stories \\n• Where feasible, create visualizations of the results\\n• Look for trends\\n• Verify that the visualization is useful for making a decision\\n3.5 Evaluate model performance (e.g., accuracy, precision)\\n• Check for overfitting, underfitting\\n• Generate metrics or KPIs\\n• Introduce new test data to cross-validate robustness, testing how model \\nhandles unforeseen data\\n3.6 Look for potential sources of bias in the algorithm\\n• Verify that inputs resemble training data\\n• Confirm that training data do not contain irrelevant correlations we do not \\nwant classifier to rely on\\n• Check for imbalances in data\\n• Guard against creating self-fulfilling prophecies based upon historical \\nbiases\\n• Check the explainability of the algorithm (e.g., feature importance in \\ndecision trees)\\n\\nCopyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. IT SPECIALIST EXAM OBJECTIVES\\n3.7 Evaluate model sensitivity \\n• Test for sensitivity of model\\n• Test for specificity of model\\n3.8 Confirm adherence to regulatory requirements, if any \\n• Evaluate outputs according to thresholds defined in requirements\\n• Document results\\n3.9 Obtain stakeholder approval\\n• Collect results and benchmark risks\\n• Hold sessions to evaluate solution\\n4. Application Integration and Deployment\\n4.1 Train customers on how to use product and what to expect from it\\n• Inform users of model limitations\\n• Inform users of intended model usage\\n• Share documentation\\n• Manage customer expectations\\n4.2 Plan to address potential challenges of models in production\\n• Understand the types of challenges you are likely to encounter\\n• Understand the indicators of challenges\\n• Understand how each type of challenge could be mitigated\\n4.3 Design a production pipeline, including application integration\\n• Create a pipeline (training, prediction) that can meet the product needs \\n(may be different from the experiment)\\n• Find the solution that works with the existing data stores and connects to \\nthe application\\n• Build the connection between the AI and the application\\n• Build mechanism to gather user feedback\\n• Test accuracy of AI through application\\n• Test robustness of AI\\n• Test speed of AI\\n• Test application to fit size of use case (e.g., in AI for mobile applications)\\n4.4 Support the AI solution\\n• Document the functions within the AI solution to allow for maintenance \\n(updates, fixing bugs, handling edge cases)\\n• Train a support team\\n• Implement a feedback mechanism\\n• Implement drift detector\\n• Implement ways to gather new data\\n5. Maintaining and Monitoring AI in Production \\n5.1 Engage in oversight\\n• Log application and model performance to facilitate security, debug, \\naccountability, and audit\\n• Use robust monitoring systems\\n\\nCopyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. IT SPECIALIST EXAM OBJECTIVES\\n• Act upon alerts\\n• Observe the system over time in a variety of contexts to check for drift or \\ndegraded modes of operation\\n• Detect any way system fails to support new information\\n5.2 Assess business impact (key performance indicators)\\n• Track impact metrics to determine whether solution has solved the \\nproblem\\n• Compare previous metrics with new metrics when changes are made\\n• Act on unexpected metrics by finding problem and fixing it\\n5.3 Measure impacts on individuals and communities\\n• Analyze impact on specific subgroups\\n• Identify and mitigate issues\\n• Identify opportunities for optimization\\n5.4 Handle feedback from users\\n• Measure user satisfaction\\n• Assess whether users are confused (e.g., do they understand what the AI is \\nsupposed to do for them?)\\n• Incorporate feedback into future versions\\n5.5 Consider improvement or decommission on a regular basis\\n• Combine impact observations (e.g., business, community, technology \\ntrends) to assess AI value\\n• Decide whether to retrain AI, continue to use AI as is, or to decommission \\nAI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memecah teks menjadi potongan-potongan kecil\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "texts = text_splitter.split_text(context)"
      ],
      "metadata": {
        "id": "7cAZD_khF0B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts))\n",
        "\n",
        "print(type(texts[0]))"
      ],
      "metadata": {
        "id": "nUyKhi6XOqGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a2cc14-2fb5-4636-ec76-e9bbb87726cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "id": "yLxW6lKZPF1q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9cb2b3f4-7304-44a9-f299-982ea5da66cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Copyright © 2023 Pearson Education, Inc. or its affiliate(s). All rights reserved. \\n1. AI Problem Definition\\n1.1 Identify the problem you are trying to solve using AI (e.g., user \\nsegmentation, improving customer service)\\n• Identify the need that will be addressed\\n• Find out what information comes in and what output is expected\\n• Determine whether AI is called for\\n• Consider upsides and downsides of AI in the situation\\n• Define measurable success'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat embeddings untuk potongan-potongan teks\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=api_key)\n",
        "\n",
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\": 20})"
      ],
      "metadata": {
        "id": "Uf49bisNF4sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index"
      ],
      "metadata": {
        "id": "X9iggyFOGH2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66cd5e44-1f42-449e-d160-f538db0e04aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x79b018b8c590>, search_kwargs={'k': 20})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(vector_index))"
      ],
      "metadata": {
        "id": "pNHWABJXQab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5eba80-733c-4143-eb85-2256da33640f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendapatkan pertanyaan dari pengguna\n",
        "user_question = input(\"Tanyakan pertanyaan: \")\n",
        "\n",
        "# Mendapatkan dokumen relevan untuk pertanyaan pengguna\n",
        "docs = vector_index.get_relevant_documents(user_question)"
      ],
      "metadata": {
        "id": "sKY_FqH8GLZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a2c071-b82d-4074-ae65-c96414cb7784"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tanyakan pertanyaan: jelaskan syarat sertifikasi AI di pearson vue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-ee8e5bac553b>:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = vector_index.get_relevant_documents(user_question)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan template prompt\n",
        "prompt_template = \"\"\"\n",
        "Jawablah pertanyaan ini dengan se-detail mungkin dari konteks yang diberikan,\n",
        "pastikan untuk memberikan semua detail, jika jawaban tidak ada dalam\n",
        "konteks yang diberikan cukup katakan, \"jawaban tidak tersedia dalam konteks\",\n",
        "jangan memberikan jawaban yang salah\\n\\n\n",
        "Konteks:\\n {context}?\\n\n",
        "Pertanyaan: \\n{question}\\n\n",
        "Jawaban:\n",
        "\"\"\"\n",
        "\n",
        "# Membuat prompt\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
        "\n",
        "# Memuat QA chain\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", api_key=api_key)\n",
        "chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "# Mendapatkan jawaban dari model\n",
        "response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
        "\n",
        "# Menampilkan jawaban\n",
        "print(\"\\nJawaban:\")\n",
        "md(response['output_text'])"
      ],
      "metadata": {
        "id": "XN8jNeFYGOKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "821bddfd-1386-4f89-907c-af10cba211b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-ac923919d070>:17: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
            "  chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
            "<ipython-input-42-ac923919d070>:20: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jawaban:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Syarat sertifikasi AI di Pearson Vue, berdasarkan konteks yang diberikan, meliputi:\n\n**Pengetahuan dan Keterampilan Prasyarat:**\n\n* Kemampuan membaca setara kelas 8.\n* Pemahaman Aljabar I.\n* Memahami bagaimana komunikasi terjadi pada jaringan.\n* Keterampilan literasi digital, termasuk kemampuan untuk meneliti, membuat konten, dan memecahkan masalah menggunakan teknologi.\n* Keterampilan berpikir komputasional, termasuk kemampuan untuk menguraikan masalah menjadi bagian-bagian yang lebih kecil dan memecahkan masalah melalui otomatisasi.\n\n**Pengalaman:**\n\n* Minimal 150 jam instruksi dan/atau eksplorasi metodologi dan solusi kecerdasan buatan.\n\n**Keterampilan Tambahan yang Membantu (tidak wajib):**\n\n* Kemampuan dalam setidaknya satu bahasa pemrograman atau scripting.\n* Keakraban dengan teknologi penyimpanan data, termasuk basis data relasional.\n* Keakraban dengan metode analisis data, termasuk statistik.\n* Keakraban dengan prinsip-prinsip keamanan, termasuk CIA (kerahasiaan, identitas, dan ketersediaan) dan AAA (Autentikasi, Otorisasi, dan Akuntansi), serta penilaian risiko dan kerentanan.\n\n\nKonteks tersebut menjelaskan detail tentang materi ujian,  tetapi tidak memberikan informasi tentang proses pendaftaran, biaya, atau persyaratan administrasi lainnya di Pearson Vue.  Informasi tersebut tidak tersedia dalam konteks."
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUkQQN2AQufW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}